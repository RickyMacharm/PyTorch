{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_Intro2DeepNeuralNets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwbtU7wZOywNW/IzE876NK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3936765606894459a65f303c519fea62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9aae5b6cdb404b9aa1961e4239b2bf3d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efe4ce21396848e9806d57c0dbaff009",
              "IPY_MODEL_38fc4ee2c5fc45749ee81b2798d8e12d"
            ]
          }
        },
        "9aae5b6cdb404b9aa1961e4239b2bf3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efe4ce21396848e9806d57c0dbaff009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_408e34f9650c4f8489afd6a0d86a1b3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2aedf007062b40b5b71a48c7cbf084eb"
          }
        },
        "38fc4ee2c5fc45749ee81b2798d8e12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_572a925e41d8408e99d899de6dc54439",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26427392/? [00:20&lt;00:00, 114424147.23it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9178bf84366b4e0284849f156204d629"
          }
        },
        "408e34f9650c4f8489afd6a0d86a1b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2aedf007062b40b5b71a48c7cbf084eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "572a925e41d8408e99d899de6dc54439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9178bf84366b4e0284849f156204d629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55776d50a7aa42928b404aaf4ee1d6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_726102ccb3b247e2b443f6399b6b5e44",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18e58adeabe741a8a7d4710376d0b3d8",
              "IPY_MODEL_4d8991eb2df54a9d96dad7648bffc708"
            ]
          }
        },
        "726102ccb3b247e2b443f6399b6b5e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18e58adeabe741a8a7d4710376d0b3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad77f28fe7e84ca285f745d2fcf82135",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c46fd89718340d5b19a2c335889f193"
          }
        },
        "4d8991eb2df54a9d96dad7648bffc708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f087f9ae813b4c898f2b65e7fba6eb6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:00&lt;00:00, 57546.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68dd4ac7fb9a4c4a96ec41a5ca2940c5"
          }
        },
        "ad77f28fe7e84ca285f745d2fcf82135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c46fd89718340d5b19a2c335889f193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f087f9ae813b4c898f2b65e7fba6eb6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68dd4ac7fb9a4c4a96ec41a5ca2940c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3693dd576514dc4a1e08ab5dbc37047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad8af78b216b4984b37d316305db5818",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ffd6e33a9c2417ea1837ec74bbf17b5",
              "IPY_MODEL_1241cd1c0aad4e36854cf0b52461616b"
            ]
          }
        },
        "ad8af78b216b4984b37d316305db5818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ffd6e33a9c2417ea1837ec74bbf17b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b17260266cc4ce6a3872cca3c121dba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_410ab28631954f3b8c5cd8785a1ef78c"
          }
        },
        "1241cd1c0aad4e36854cf0b52461616b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62383982e90847fc891185e3977c9169",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4423680/? [00:00&lt;00:00, 9653223.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bb260992bfa43cba543e75a82e21423"
          }
        },
        "9b17260266cc4ce6a3872cca3c121dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "410ab28631954f3b8c5cd8785a1ef78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62383982e90847fc891185e3977c9169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bb260992bfa43cba543e75a82e21423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51cb441373274a6686ae3af85437025d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26412c48c4dd4be69ed467be9f115226",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed69c415341a438999d9d1c03ad01789",
              "IPY_MODEL_8f844cd6e70648edb44572d4c1c14c86"
            ]
          }
        },
        "26412c48c4dd4be69ed467be9f115226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed69c415341a438999d9d1c03ad01789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4cf45c28d83c414a94b6af47a23d833c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_738fbf6e058a4f42a64c6c5f30a409af"
          }
        },
        "8f844cd6e70648edb44572d4c1c14c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d786ae16b68342109897571a6cb94a7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 36243.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d23305381d0474691acb2440a031fca"
          }
        },
        "4cf45c28d83c414a94b6af47a23d833c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "738fbf6e058a4f42a64c6c5f30a409af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d786ae16b68342109897571a6cb94a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d23305381d0474691acb2440a031fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RickyMacharm/PyTorch/blob/master/05_Intro2DeepNeuralNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLSKlFROUP-",
        "colab_type": "text"
      },
      "source": [
        "### **Dealing with Neural Networks**\n",
        "Deep learning is a class of machine learning algorithms that is designed to loosely mimic\n",
        "the neurons in our brain. \n",
        "\n",
        "A neuron takes an input from a number of inputs from\n",
        "surrounding neurons and sums it up, and if the sum exceeds a certain threshold, then the\n",
        "neuron fires. Between each neuron there is a gap called a synapse.\n",
        "\n",
        "Signals are carried across\n",
        "these synapses by neurotransmitter chemicals, and the amount and type of these chemicals\n",
        "will dictate how strong the input to the neuron is. \n",
        "\n",
        "The function of the biological neural\n",
        "network is replicated by artificial neural networks using weights, biases (a bias is defined as\n",
        "a weight multiplied by a constant input of 1), and activation functions.\n",
        "The following is a diagrammatic representation of a neural unit:\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1WyEkqvBsBx_Kzsl5GkhVpihBObyNX6V9)\n",
        "\n",
        "All a neural network sees are sets of numbers, and it tries to identify a pattern in the data.\n",
        "\n",
        "Through training, the neural network learns to recognize a pattern in the input; however,\n",
        "there are certain specialized architectures that perform better when applied to a certain\n",
        "category of problems than others. \n",
        "\n",
        "A simple neural network architecture consists of three\n",
        "kinds of layer: the **input layer**, the **output layer**, and the **hidden layer**. When there is more\n",
        "than one hidden layer, it is called a **deep neural network**.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1DkRXCm69pDrquYEd5kFB34kYf_oUGRxa)\n",
        "\n",
        "In the preceding diagram the circles represent a neuron or in deep learning terms, a node,\n",
        "which is a computation unit. The edges represent the connection between the nodes and\n",
        "hold the connection weight (synapse strength) between the two nodes.\n",
        "\n",
        "Here are the stuff we will work with in this segment:\n",
        "\n",
        "* Defining the neural network class\n",
        "* Creating a fully connected network\n",
        "* Defining the loss function\n",
        "* Implementing optimizers\n",
        "* Implementing dropouts\n",
        "* Implementing functional APIs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1pBCzplRP38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MvR4m6YW_MQ",
        "colab_type": "text"
      },
      "source": [
        "**transforms:** An abstract class representing a Dataset.\n",
        "It just a class which holds the data, on which Pytorch can perform manipulations.\n",
        "Transforms are the methods which can be used to transform data from the dataset. \n",
        "\n",
        "The `transforms` module helps with a lot of\n",
        "image preprocessing tasks. For the particular case that we are dealing with, an image\n",
        "consisting of 28 x 28 grayscale pixels, we first need to read from the image and convert it\n",
        "into a tensor using a `transforms.ToTensor()` transform. We then make the mean and\n",
        "standard deviation of the pixel values 0.5 and 0.5 respectively so that it becomes easier for\n",
        "the model to train; to do this, we use `transforms.Normalize((0.5,),(0.5,))`. We\n",
        "combine all of the transformations together with `transform.Compose()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-PBHV9JVrhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), \n",
        "                                transforms.Normalize((0.5,), (0.5,)),])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwOMTJoxZbMA",
        "colab_type": "text"
      },
      "source": [
        "We want to feed our model in chunks, so  let's define the batch_size to divide our dataset into those chunks.\n",
        "\n",
        "With the transforms ready, we defined a suitable batch size. A higher batch size means that\n",
        "the model has fewer training steps and learns faster, even though it also means\n",
        "high memory requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtKGov2QZTqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCXdAmoUZvqi",
        "colab_type": "text"
      },
      "source": [
        "we will pull the dataset from `torchvision` and apply the transform and\n",
        "create batches. \n",
        "\n",
        "TorchVision comes with a lot of popular datasets in its datasets module; if it's not\n",
        "available on the machine, it will download it for you, pass the transformations, and convert\n",
        "the data into the desired format for the model to train on. \n",
        "\n",
        "In our case, the dataset comes\n",
        "with a training and testing set, and we load them accordingly. \n",
        "\n",
        "We use\n",
        "`torch.utils.data.DataLoader` to load this processed data into batches, along with\n",
        "other operations such as shuffling and loading to the right deviceâ€”CPU or GPU.\n",
        "\n",
        "We will first create a training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2iDIZNHZpT4",
        "colab_type": "code",
        "outputId": "4d588137-ae51-4269-fd70-1367c9bc13d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "3936765606894459a65f303c519fea62",
            "9aae5b6cdb404b9aa1961e4239b2bf3d",
            "efe4ce21396848e9806d57c0dbaff009",
            "38fc4ee2c5fc45749ee81b2798d8e12d",
            "408e34f9650c4f8489afd6a0d86a1b3d",
            "2aedf007062b40b5b71a48c7cbf084eb",
            "572a925e41d8408e99d899de6dc54439",
            "9178bf84366b4e0284849f156204d629",
            "55776d50a7aa42928b404aaf4ee1d6d8",
            "726102ccb3b247e2b443f6399b6b5e44",
            "18e58adeabe741a8a7d4710376d0b3d8",
            "4d8991eb2df54a9d96dad7648bffc708",
            "ad77f28fe7e84ca285f745d2fcf82135",
            "2c46fd89718340d5b19a2c335889f193",
            "f087f9ae813b4c898f2b65e7fba6eb6e",
            "68dd4ac7fb9a4c4a96ec41a5ca2940c5",
            "c3693dd576514dc4a1e08ab5dbc37047",
            "ad8af78b216b4984b37d316305db5818",
            "3ffd6e33a9c2417ea1837ec74bbf17b5",
            "1241cd1c0aad4e36854cf0b52461616b",
            "9b17260266cc4ce6a3872cca3c121dba",
            "410ab28631954f3b8c5cd8785a1ef78c",
            "62383982e90847fc891185e3977c9169",
            "9bb260992bfa43cba543e75a82e21423",
            "51cb441373274a6686ae3af85437025d",
            "26412c48c4dd4be69ed467be9f115226",
            "ed69c415341a438999d9d1c03ad01789",
            "8f844cd6e70648edb44572d4c1c14c86",
            "4cf45c28d83c414a94b6af47a23d833c",
            "738fbf6e058a4f42a64c6c5f30a409af",
            "d786ae16b68342109897571a6cb94a7e",
            "2d23305381d0474691acb2440a031fca"
          ]
        }
      },
      "source": [
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', \n",
        "                                 download=True, train=True, transform=transform)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3936765606894459a65f303c519fea62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55776d50a7aa42928b404aaf4ee1d6d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3693dd576514dc4a1e08ab5dbc37047",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51cb441373274a6686ae3af85437025d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2of4fLjaJa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, \n",
        "                                          batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zu4Bc0oaTbw",
        "colab_type": "text"
      },
      "source": [
        "create the `testset`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91-NKVpfaOd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', \n",
        "                                download=True, train=False, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py6J5IPkadel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, \n",
        "                                         batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3nN_bZqamSX",
        "colab_type": "text"
      },
      "source": [
        "Now our main task is to define the neural network class, which has to be a\n",
        "subclass of `nn.Module`.\n",
        "\n",
        "We could define the model class with any name, but what is important is that it is a\n",
        "subclass of `nn.Module` and has `super().__init__()`, which provides the model with a\n",
        "lot of useful methods and attributes and retains knowledge of the architecture.\n",
        "\n",
        "```python\n",
        "class FashionNetwork(nn.Module):\n",
        "  ```\n",
        "we define the `init` method for the class:\n",
        "```pytorch\n",
        "def __init__(self):\n",
        "  super().__init__()\n",
        "```\n",
        "define the layers for our model within `init`. The first hidden layer\n",
        "looks like the following:\n",
        "```python\n",
        "self.hidden1 = nn.Linear(784, 256)\n",
        "```\n",
        "We use `nn.Linear()` to define fully connected layers by passing in the input and output\n",
        "dimensions. We use a softmax layer for the last layer output because there are 10 output\n",
        "classes. We use ReLU activation in the layers before the output layer to learn nonlinearity in\n",
        "the data. The `hidden1` layer takes 784 inputs units and gives out 256 output units. The\n",
        "`hidden2` phrase outputs 128 units and the output layer has 10 output units representing 10\n",
        "output classes. The softmax layer converts the activations into probabilities so that it adds\n",
        "to 1 along dimension 1.\n",
        "\n",
        "define the second hidden layer:\n",
        "```python\n",
        "self.hidden2 = nn.Linear(256, 128)\n",
        "```\n",
        "define our output layer:\n",
        "```python\n",
        "self.output = nn.Linear(128, 10)\n",
        "```\n",
        "define our softmax activation for our last layer:\n",
        "```python\n",
        "self.softmax = nn.Softmax(dim=1)\n",
        "```\n",
        "Finally, we will define the activation function in the inner layers:\n",
        "```python\n",
        "self.activation = nn.ReLU()\n",
        "```\n",
        "With these steps, we have completed our network units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xq0NXJdakjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.output = nn.Linear(128, 10)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.activation = nn.ReLU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4MWNNfhgRX1",
        "colab_type": "text"
      },
      "source": [
        "### **Fully Connected Network**\n",
        "we will expand on the class that we defined in the previous section.\n",
        "\n",
        "we only created\n",
        "components of the architecture that we needed; now we will look at tying all these pieces\n",
        "together to make a sensible network. \n",
        "\n",
        "The progression for our layers will be from 784 units\n",
        "to 256, then to 128, and finally the output layer of 10 units.\n",
        "\n",
        "the network is completed by setting up a `forward` network, wherein we tied\n",
        "together the network components defined in the constructor. A network defined with\n",
        "`nn.Module` needs to have a `forward()` method defined. It takes the input tensor and\n",
        "passes it through the network components defined in the `__init__()` method in the\n",
        "network class, in the sequence of operations defined in the forward method.\n",
        "\n",
        "The `forward` method is called automatically when input is passed referring to the name of\n",
        "the model object. \n",
        "\n",
        "The `forward` function is where all the magic happens. This is where the data enters and is fed into the computation graph (i.e., the neural network structure we have built).\n",
        "\n",
        "The `nn.Module` automatically creates the weight and bias tensors that\n",
        "we'll use in the forward method. \n",
        "\n",
        "The linear unit by itself defines a linear function, such\n",
        "as $xW + B$; to have nonlinear capabilities, we need to insert nonlinear activation functions,\n",
        "and here we use one of the most popular activation functions, `ReLU`, although you could\n",
        "use other available activation functions in PyTorch.\n",
        "\n",
        "Let's start with the `forward()` method in the class, passing in the input:\n",
        "\n",
        "```python\n",
        "def forward(self, x):\n",
        "```\n",
        "\n",
        "we will move the input to the first hidden layer, with 256 nodes:\n",
        "```python\n",
        "x = self.hidden1(x)\n",
        "```\n",
        "Next, we pass the outputs from the first hidden layer through the activation\n",
        "function, which in our case is ReLU:\n",
        "```python\n",
        "x = self.activation(x)\n",
        "```\n",
        "\n",
        "We will repeat the same for the second layer, which has 128 nodes, and pass it\n",
        "through ReLU:\n",
        "```python\n",
        "x = self.hidden2(x)\n",
        "x = self.activation(x)\n",
        "```\n",
        "\n",
        "Now we pass the last output layer, with 10 output classes:\n",
        "```python\n",
        "x = self.output(x)\n",
        "```\n",
        " Then we will push the output using the softmax function:\n",
        "```python\n",
        "output = self.softmax(x)\n",
        "```\n",
        "we return the output tensor:\n",
        "```python\n",
        "return output\n",
        "```\n",
        "\n",
        "We will then create the network object:\n",
        "```python\n",
        "model = FashionNetwork()\n",
        "```\n",
        "Our input layer has 784 units (from 28 x 28 pixels), and the first layer has 256 units with\n",
        "ReLU activation, then 128 units with ReLU activation, and finally 10 units with softmax\n",
        "activation. The reason we squish the final layer output through softmax is because we want\n",
        "to have 1 output class with a higher probability than all the other classes, and the sum of\n",
        "the output probabilities should equal 1. The softmax function has a parameter `dim=1` that\n",
        "ensures that softmax is taken across the columns of the output. We then create an object\n",
        "using the model class and print the details of the class using `print(model)`.\n",
        "\n",
        "Let's have a quick look at our model:\n",
        "```python\n",
        "print(model)\n",
        "FashionNetwork(\n",
        "    (hidden1): Linear(in_features=784, out_features=256,\n",
        "bias=True)\n",
        "    (hidden2): Linear(in_features=256, out_features=128,\n",
        "bias=True)\n",
        "    (output): Linear(in_features=128, out_features=10,\n",
        "bias=True)\n",
        "    (softmax): Softmax()\n",
        "    (activation): ReLU()\n",
        ")\n",
        "```\n",
        "\n",
        "We can define the network architecture without defining a network class using the\n",
        "`nn.Sequential` module, and it is important to ensure that the sequence of operation in\n",
        "the forward method is ordered properly, although the sequence doesn't matter in\n",
        "`__init__`. You can use `nn.Tanh` for tanh activation. You can access the weight and bias\n",
        "tensors from the model object with `model.hidden.weight` and `model.hidden.bias`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFhnqxOLnKH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.output = nn.Linear(128, 10)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.hidden1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.output(x)\n",
        "    output = self.softmax(x)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGxdRAV3qkbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = FashionNetwork()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMmr33WPqr_p",
        "colab_type": "code",
        "outputId": "f8a612bd-e6d2-4d1f-ffeb-ecee1194f0df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FashionNetwork(\n",
            "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (hidden2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            "  (activation): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVD1OPFtvAk-",
        "colab_type": "text"
      },
      "source": [
        "### **Defining the loss function**\n",
        "\n",
        "A machine learning model, when being trained, may have some deviation between the\n",
        "predicted output and the actual output, and this difference is called the **error** of the model.\n",
        "\n",
        "The function that lets us calculate this error is called the **loss function**, or **error function**.\n",
        "This function provides a metric to evaluate all possible solutions and choose the most\n",
        "optimized model. \n",
        "\n",
        "The loss function has to be able to reduce all attributes of the model\n",
        "down to a single number so that an improvement in that loss function value is\n",
        "representative of a better model.\n",
        "\n",
        "Let us define a loss function for our fashion dataset using the loss function\n",
        "available in PyTorch.\n",
        "\n",
        "We will define our loss function thus:\n",
        "\n",
        "* First, we will modify our existing network architecture to the output log of\n",
        "softmax instead of softmax, starting with the __init__ method in the network\n",
        "constructor:\n",
        "\n",
        "```python\n",
        "self.log_softmax = nn.LogSoftmax()\n",
        "```\n",
        "\n",
        "* Next, we will make the same change in the forward method of the neural\n",
        "network:\n",
        "```python\n",
        "output = self.log_softmax(x)\n",
        "```\n",
        "\n",
        "We will use the cell to display our final code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLqf1hJ8qvmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.output = nn.Linear(128, 10)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.hidden1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.output(x)\n",
        "    output = self.log_softmax(x)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km_aSKB-Jokx",
        "colab_type": "text"
      },
      "source": [
        "We define the model object as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH8S4OSRI-SV",
        "colab_type": "code",
        "outputId": "98d8f24c-7fea-43e9-d771-074309918b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "model = FashionNetwork(); model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionNetwork(\n",
              "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (hidden2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (log_softmax): LogSoftmax()\n",
              "  (activation): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ01HeqlJ90i",
        "colab_type": "text"
      },
      "source": [
        "Now, we will define our loss function; we will use negative log likelihood loss\n",
        "for this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TXeVrswJ2wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCYHHbu_KCHm",
        "colab_type": "text"
      },
      "source": [
        "We now have our loss function ready.\n",
        "\n",
        "We replaced softmax with log softmax so that we could then use the log of\n",
        "probabilities over probabilities, which has nice theoretic interpretations. \n",
        "\n",
        "There are various\n",
        "reasons for doing this, including improved numerical performance and gradient\n",
        "optimization. These advantages can be extremely important when training a model that can\n",
        "be computationally challenging and expensive. \n",
        "\n",
        "Furthermore, it has a high penalizing effect\n",
        "when it is not predicting the correct class.\n",
        "We therefore use negative log likelihood when dealing with log softmax, as softmax is not\n",
        "compatible. \n",
        "\n",
        "It is useful in classification between n number of classes. The log would ensure\n",
        "that we are not dealing with very small values between 0 and 1, and negative values would\n",
        "ensure that a logarithm of probability that is less than 1 is nonzero. \n",
        "\n",
        "Our goal would be to\n",
        "reduce this negative log loss error function. In PyTorch, the loss function is called a\n",
        "criterion, and so we named our loss function criterion.\n",
        "\n",
        "We can provide an optional argument, weight, that has to be a 1D tensor that assigns\n",
        "weights to each of the output classes to deal with unbalanced training sets.\n",
        "\n",
        "### **Implementing optimizers**\n",
        "**Backpropagation** is a method by\n",
        "which the neural networks learn from errors; the errors are used to modify weights in such\n",
        "a way that the errors are minimized.\n",
        "\n",
        "`Optimization` functions are responsible for modifying\n",
        "weights to reduce the error. Optimization functions calculate the partial derivative of errors\n",
        "with respect to weights. The derivative shows the direction of a positive slope, and so we\n",
        "need to reverse the direction of the gradient. \n",
        "\n",
        "The optimizer function combines the model\n",
        "parameters and loss function to iteratively modify the model parameters to reduce the\n",
        "model error. Optimizers can be thought of as fiddling with the model weights to get the\n",
        "best possible model based on the difference in prediction from the model and the actual\n",
        "output, and the loss function acts as a guide by indicating when the optimizer is going right\n",
        "or wrong.\n",
        "\n",
        "The `learning rate` is a hyperparameter of the optimizer, which controls the amount by\n",
        "which the weights are updated. The learning rate ensures that the weights are not updated\n",
        "by a huge amount so that the algorithm fails to converge at all and the error gets bigger and\n",
        "bigger; however at the same time, the updating of the weight should not be so low that it\n",
        "takes forever to reach the minimum of the cost function/error function.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1CY1o1eGIH09_nwhQyWNJBIOfdyMBagxA)\n",
        "\n",
        "\n",
        "\n",
        "We will start by importing the `optim` module:\n",
        "```python\n",
        "from torch import optim\n",
        "```\n",
        "Next, we will create an optimizer object. We will use the Adam optimizer and pass\n",
        "model parameters:\n",
        "```python\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "```\n",
        "To check for the defaults of the optimizer, you can do the following:\n",
        "```python\n",
        "optimizer.defaults\n",
        "```\n",
        "output\n",
        "```python\n",
        "{'lr': 0.001,\n",
        "'betas': (0.9, 0.999),\n",
        "'eps': 1e-08,\n",
        "'weight_decay': 0,\n",
        "'amsgrad': False}\n",
        "```\n",
        "You can also add the learning rate as an additional parameter:\n",
        "```python\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-3)\n",
        "```\n",
        "Now we will start training our model, starting with the number of epochs:\n",
        "```python\n",
        "epoch = 10\n",
        "```\n",
        " We will then start the loop:\n",
        "```python\n",
        "for _ in range(epoch):\n",
        "```\n",
        " We initialize running_loss as 0:\n",
        "```python\n",
        "running_loss = 0\n",
        "```\n",
        "We will iterate through each image in training the image loader, which we defined\n",
        "in an earlier recipe in this chapter: Defining the neural network class:\n",
        "```python\n",
        "for image, label in trainloader:\n",
        "  ```\n",
        "We then reset the gradients to zero:\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "```\n",
        " Next, we will reshape the image:\n",
        "```python\n",
        "image = image.view(image.shape[0],-1)\n",
        "```\n",
        "Then we get the prediction from the model:\n",
        "```python\n",
        "pred = model(image)\n",
        "```\n",
        "Then we calculate the loss/error:\n",
        "```python\n",
        "loss = criterion(pred, label)\n",
        "```\n",
        "Then we call the .backward() method on the loss:\n",
        "```python\n",
        "loss.backward()\n",
        "```\n",
        "Then we call the .step() method on the optimizer:\n",
        "```python\n",
        "optimizer.step()\n",
        "```\n",
        "Then we append to the running loss:\n",
        "```python\n",
        "running_loss += loss.item()\n",
        "```\n",
        "Finally, we will print the loss after each epoch:\n",
        "```python\n",
        "else:\n",
        "    print(f'Training loss: {running_loss/len(trainloader):.4f}')\n",
        "```\n",
        "The following is a sample output:\n",
        "```python\n",
        "Training loss: 0.4978\n",
        "Training loss: 0.3851\n",
        "Training loss: 0.3498\n",
        "Training loss: 0.3278\n",
        "Training loss: 0.3098\n",
        "Training loss: 0.2980\n",
        "Training loss: 0.2871\n",
        "Training loss: 0.2798\n",
        "Training loss: 0.2717\n",
        "Training loss: 0.2596\n",
        "```\n",
        "Now we have completed the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8o2X6gVKEkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLBjY-x7EA0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "77d56d09-1cd4-455d-ec8c-265e7306e22b"
      },
      "source": [
        "optimizer.defaults"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amsgrad': False,\n",
              " 'betas': (0.9, 0.999),\n",
              " 'eps': 1e-08,\n",
              " 'lr': 0.001,\n",
              " 'weight_decay': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buv16NDgETK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=3e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHJlgNwlEjn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTLHQ-VFEscz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "750950ed-4584-4b38-928e-e23c671b69b9"
      },
      "source": [
        "for _ in range(epoch):\n",
        "  running_loss = 0\n",
        "  for image, label in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    image = image.view(image.shape[0],-1)\n",
        "    pred = model(image)\n",
        "    loss = criterion(pred, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(f'Training loss: {running_loss/len(trainloader):.4f}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.1955\n",
            "Training loss: 0.1947\n",
            "Training loss: 0.1933\n",
            "Training loss: 0.1926\n",
            "Training loss: 0.1934\n",
            "Training loss: 0.1870\n",
            "Training loss: 0.1839\n",
            "Training loss: 0.1793\n",
            "Training loss: 0.1782\n",
            "Training loss: 0.1724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLeAo2yRQmRa",
        "colab_type": "text"
      },
      "source": [
        "We started by defining the optimizer using an **`Adam optimizer`**, and then we\n",
        "set a learning rate for the optimizer and had a look at the default parameters. We set an\n",
        "epoch of 10 and started iterations for each epoch, setting `running_loss` to 0 on each\n",
        "iteration and iterating over each image within the epoch (the number of times the model\n",
        "sees the dataset). We started by clearing the gradients using the `.zero_grad()` method.\n",
        "PyTorch accumulates gradients on each backward pass, which is useful in some cases, and\n",
        "so it was imported to zero out the gradient to properly update the model parameters.\n",
        "\n",
        "Next, we reshaped the image by flattening each batch of 64 images (consisting of 28 x 28\n",
        "pixels in each image) to 784, thereby changing the tensor shape from 64 x 28 x 28 to 64 x\n",
        "784, as our model expects this shape for the input. Next, we sent this input over to the\n",
        "model and got the output predictions for the batch from the model, and then passed it to\n",
        "the loss function, also called criterion; there, it assessed the difference between the\n",
        "predicted and the actual class.\n",
        "The `loss.backward()` function calculated the gradientâ€”that is, the partial derivative of\n",
        "the error with respect to the weightsâ€”and we called the `optimizer.step() function` to\n",
        "update the weights of the model to adapt to the error that was evaluated. The `.item()`\n",
        "method pulled a scalar out of a single element tensor, and so with `loss.item()` we get a\n",
        "scalar value of error from the batch, accumulate it to the losses through all the batches,\n",
        "and finally print the loss at the end of the epoch.\n",
        "\n",
        "We can use a callback function called closure as a parameter for `.step(closure)` to\n",
        "calculate the loss and update the weights by passing in a function as a parameter. we\n",
        "could also explore other optimizer functions, such as Adadelta, Adagrad, SGD, and so on,\n",
        "which are available with PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wRAiwQYSgB1",
        "colab_type": "text"
      },
      "source": [
        "## **Implementing dropouts**\n",
        "We will look at implementing dropouts. One of the more common\n",
        "phenomena that we might encounter while training a neural network model, or any\n",
        "machine learning model in general, is overfitting. Overfitting happens when a model learns\n",
        "the data that is given to it for training rather than generalizing on the solution spaceâ€”that\n",
        "is, it learns the minute details and noises of the training data, instead of grasping the bigger\n",
        "picture, and so performs poorly on new data. \n",
        "\n",
        "Regularization is the process of preventing\n",
        "models from overfitting.\n",
        "Using a dropout is one of the most popular regularization techniques in neural networks, in\n",
        "which randomly selected neurons are turned off while trainingâ€”that is, the contribution of\n",
        "neurons is temporarily removed from the forward pass and the backward pass doesn't\n",
        "affect the weights, so that no single neuron or subset of neurons gets all the decisive power\n",
        "of the model; rather, all the neurons are forced to make active contributions to predictions.\n",
        "\n",
        "Dropouts can be intuitively understood as creating a large number of ensemble models,\n",
        "learning to capture various features under one big definition of a model.\n",
        "In this recipe, we will look at how to add dropouts to our model definition to improve the\n",
        "overall model performance by preventing overfitting. It should be remembered that\n",
        "dropouts are to be applied only while training; however, when testing and during the\n",
        "actual prediction, we want all of the neurons to make contributions.\n",
        "\n",
        "We will start with our initial model definition:\n",
        "```python\n",
        "class FashionNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.output = nn.Linear(128, 10)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.hidden1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.output(x)\n",
        "    output = self.log_softmax(x)\n",
        "    return output\n",
        "```\n",
        "\n",
        "Then we will add a dropout to our model `__init__:`\n",
        "```python\n",
        "self.drop = nn.Dropout(p=0.25)\n",
        "```\n",
        "\n",
        "Our updated` __init__()` looks as follows:\n",
        "```python\n",
        "def __init__(self):\n",
        "  super().__init__()\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.output = nn.Linear(128, 10)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "    self.activation = nn.ReLU()\n",
        "    self.drop = nn.Dropout(p=0.25)\n",
        "\n",
        "```\n",
        "\n",
        " Now, we will add dropouts in our forward() method:\n",
        "```python\n",
        "def forward(self, x):\n",
        "  x = self.hidden1(x)\n",
        "  x = self.activation(x)\n",
        "  x = self.drop(x)\n",
        "  x = self.hidden2(x)\n",
        "  x = self.activation(x)\n",
        "  x = self.drop(x)\n",
        "  x = self.output(x)\n",
        "  output = self.log_softmax(x)\n",
        "  return output\n",
        "```\n",
        "We now have a network with dropouts.\n",
        "\n",
        "we altered the` __init__()` method to add the dropout layer with a dropout\n",
        "probability of 0.25, which means that 25% of the neurons in the layer where this dropout is\n",
        "applied will be turned off randomly. Then, we edited our forward function, applied it to\n",
        "the first hidden layer with 256 units in it, and then we applied the dropout on the second\n",
        "layer, which has 128 units. We applied the activation in both the layers after going through\n",
        "the activation functions. We have to keep in mind that dropouts must be applied only on\n",
        "hidden layers in order to prevent us from losing the input data and missing outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAWm6w6hLLbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.output = nn.Linear(128, 10)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "    self.activation = nn.ReLU()\n",
        "    self.drop = nn.Dropout(p=0.25)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.hidden1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.output(x)\n",
        "    output = self.log_softmax(x)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQC5uWAKXcau",
        "colab_type": "text"
      },
      "source": [
        "### **Implementing functional APIs**\n",
        "We will explore functional APIs in PyTorch; doing so will allow us to write\n",
        "cleaner and more concise network architectures and components. We will be looking at\n",
        "functional APIs and defining models, or a part of a model, with functional APIs.\n",
        "\n",
        "In the following steps, we use our existing neural network class definition and then rewrite\n",
        "it using functional APIs:\n",
        "\n",
        "We will start by making an import:\n",
        "```python\n",
        "import torch.nn.functional as F\n",
        "```\n",
        "Then we define our FashionNetwork class with `F.relu()` and `F.log_softmax()`:\n",
        "```pthon\n",
        "class FashionNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784,256)\n",
        "    self.hidden2 = nn.Linear(256,128)\n",
        "    self.output = nn.Linear(128,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.hidden1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = F.log_softmax(self.output(x))\n",
        "    return x\n",
        "```\n",
        "We redefined our model with functional APIs.\n",
        "\n",
        "we defined the exact same network as before, but replaced the activation\n",
        "function and the log softmax with `function.relu` and `function.log_softmax`, which\n",
        "makes our code look a lot cleaner and more concise.\n",
        "\n",
        "You could use functional APIs for linear layers by using `functional.linear()` and\n",
        "`functional.dropout()` to control dropouts, but you must take care to pass the model\n",
        "state to indicate whether it is in training or evaluation/prediction mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj1S6iKXYzbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLe1pE_DY5mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784,256)\n",
        "    self.hidden2 = nn.Linear(256,128)\n",
        "    self.output = nn.Linear(128,10)\n",
        " \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.hidden1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = F.log_softmax(self.output(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}